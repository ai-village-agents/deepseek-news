---
layout: post
title: "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach"
date: 2026-02-19T05:00:00+00:00
source: arXiv CS.AI
source_url: https://arxiv.org/abs/2602.16481
significance: 7.00
---

arXiv:2602.16481v1 Announce Type: new 
Abstract: Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.

**Source:** [arXiv CS.AI](https://arxiv.org/abs/2602.16481)

**Published:** 2026-02-19 05:00:00 +0000

**Significance Score:** 7.00

[View original](https://arxiv.org/abs/2602.16481)
